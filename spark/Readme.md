# Spark
# 스파크 
- 빅데이터 애플리케이션 개발에 필요한 통합 플랫폼을 제공
- 간단한 데이터 읽기에서부터 SQL처리, 머신러닝 그리고 스트림 처리에 이르기까지 다양한 데이터 분석 작업을 같은 연산 엔진과 일관성 있는 API로 수행
- 클라우드 기반의 애저 스토리지, 아마존 S3, 분산 파일 시스템인 아파치 하둡, 키/값 저장소인 아파치 카산드라, 메시지 전달 서비스인 아파치 카프카등의 저장소 지원
- 빅데이터 애플리케이션에 필요한 대부분의 기능을 지원 
  - 실시간 데이터 처리 기능(Spark Streaming)
  - 스파크SQL : SQL과 구조화된 데이터를 제공
  - MLlib : 머신러닝 지원
  - GraphX : 스트림 처리 기능을 제공하는 스파크 스트리밍과 새롭게 선보인 구조적 스트리밍 그리고 그래프 분석 엔진
- 인메모리 기반의 대용량 데이터 고속 처리 엔진
- 아파치 스파크는 오픈 소스 범용 분산 클러스터 컴퓨팅 프레임워크
- 아파치 스파크는 범용적이면서도 빠른 속도로 작업을 수행할수 있도록 설계한 클러스터용 플랫폼이자 스트림 처리를 효과적으로 수행하는 인-메모리 방식의 분산 처리 시스템
- 최초 데이터 로드와 최종 결과 저장시에만 디스크 사용 

# 하둡과 비교
- 스파크 메모리 내 데이터 고속 처리 엔젠은 특정 상황, 스테이지 간 다중 스테이지 작업과 비교 시 맵리듀스에 비해 최대 100배 더 빠름
- 아파치 스파크 API는 맵리듀스와 다른 아파치 하둡 구성 요소에 비해 개발자 친화적 API를 제공하여 분산 처리 엔진의 복잡성 대부분을 간단한 메서드를 처리
- 아파치 스파크의 중심은 컴퓨팅 크러스터로 분할 가능한 불변적 객체 컬렉션을 나타내는 프로그래밍 추상화, 즉 탄력적 분산 데이터 집합(RDD) 개념
- 스파크 SQL은 구조적 데이터 처리에 초점을 두며,R과 python에서 차용한 데이터 프레임을 사용
- 스파크 SQL은 표준 SQL 지원 외에 기본적으로 지원되는 JSON, HDFS, 아파치 하이브, JDBC, 아파치 ORC, 아파치 파케이를 포함한 다른 데이터 저장소에서 읽기와 쓰기를 위한 표준 인터페이스도 제공

# 스파크 구조
- Spark Core
  - 메모리 기반의 분산 클러스터 컴퓨팅 환경
  - 스파크 전체의 기초가 되는 기초 분산 작업 처리
  - 장애복구, 네트워킹, 보안, 스케쥴링 및 데이터 셔플링 등 기본 기능을 제공 
- Spark SQL
  - 대규 분산 정형 데이터 처리
  - JSON 파일, Parquet 파일, RDB 테이블, 하이브 테이블 등 다양한 데이터 읽기 및 쓰기 가능
- Spark Streamin
  - 실시간 스트리밍 데이터를 처리하는 프레임워크
  - HDFS, 아파치 카프카, 아파치 플럼, 트위터, ZeroMQ 와 더블어 커스텀 리소스 사용 가능 
 - Spark MLlib
  - 머신러닝 알고리즘 라이브러리
  - RDD 또는 DataFrame의 데이터셋을 변환하는 머신 러닝 모델을 구현
- Spark GraphX
  - 그래프 장점과 두 정점을 잇는 간선으로 구성된 데이터 구조
  - 그래프 RDD(EdgeRDD 및 VertexRDD) 형태의 그래프 구조를 만들 수 있는 기능을 제공
  - 그래프 데이터는 Vertex와 Edge로 구성 
- 동작 구조
  - Driver Program : SparkContext와 RDD 생성, Transformation과 Action을 실행
    - SparkContext : 어떻게 클러스터에 접근할 수 있는지 알려주는 Object, Worker Node내 Executor 간 통신이 발생 
  - Cluster Manager : 클러스터에 1개 존재, 스케쥴링 담당, 여러 대의 서버로 구성된 클러스터 환경에서 다수의 Application이 함께 구동될 수 있게 Application간의 CPU나 메모리, 디스크와 같은 전반적인 컴퓨팅 자원 관리
    - Standalone : 스파크가 독립적으로 작동할 수 있음
    - YARN : 하둡의 리소스 매니저 (하둡과 스파크는 상호 독립적)
    - Mesos : 분산 커널 시스템
    - Kubernetes
  - Worker Node
    - 실제 작업을 수행하는 노드
    - Executor 
      - 주어진 스파크 작업의 개별 테스크들을 실행하는 작업실행 프로세스
      - 애플리케이션을 구성하는 작업을 실행 -> 드라이버에 결과를 전송
      - 사용자 프로그램에서 캐시하는 RDD를 저장하기 위한 메모리 저장소 제공 
    - Task : executor에 할당 되는 작업의 단위 
