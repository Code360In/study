{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7OVNYKGjrPObLeyA6Nj/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjs1995/study/blob/main/study/tree/main/spark/pyspark_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV2lpGCI4oru"
      },
      "source": [
        "# pyspark\n",
        "- https://sparkbyexamples.com/pyspark/pyspark-when-otherwise/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leqPOkMYLpC0",
        "outputId": "37188ad7-2453-4b92-b502-502bc7b5910c"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 46.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=e27fd9ac7b9d9ce8bde2986cea67ce179ae35a47870bce676ffcd24c7f48ca14\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6A0z5lTLwVl"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "                    .master('local[*]')\\\n",
        "                    .appName('hello_world_app')\\\n",
        "                    .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPmXlu8YMAH9"
      },
      "source": [
        "values = [(\"2021-08-03\",\"a\", 23, 20), (\"2021-09-03\",\"b\", 45,10), (\"2021-10-03\",\"c\", 10,20), (\"2021-11-03\",\"d\", 60,20), (\"2021-08-23\",\"e\", -99,-99), (\"2021-09-13\",\"f\", 2,10), (\"2021-11-23\",\"g\", 25,20), (\"2021-11-23\",\"h\", 40,10), (\"2021-09-05\",\"j\", 33,-99)]\n",
        "df = spark.createDataFrame(values, [\"date\",\"name\", \"ages\",'gender'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g_LeNk8Mq_3",
        "outputId": "15c9f3f1-d93c-4020-ab38-738f8eed835d"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+----+------+\n",
            "|      date|name|ages|gender|\n",
            "+----------+----+----+------+\n",
            "|2021-08-03|   a|  23|    20|\n",
            "|2021-09-03|   b|  45|    10|\n",
            "|2021-10-03|   c|  10|    20|\n",
            "|2021-11-03|   d|  60|    20|\n",
            "|2021-08-23|   e| -99|   -99|\n",
            "|2021-09-13|   f|   2|    10|\n",
            "|2021-11-23|   g|  25|    20|\n",
            "|2021-11-23|   h|  40|    10|\n",
            "|2021-09-05|   j|  33|   -99|\n",
            "+----------+----+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehLPXWZqMxaj"
      },
      "source": [
        "# 나이 구분 \n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "def categorizer(ages):\n",
        "  if ages < 10:\n",
        "    return \"정보없음\"\n",
        "  elif ages < 20:\n",
        "    return \"10대\"\n",
        "  elif ages < 30:\n",
        "    return \"20대\"\n",
        "  elif ages < 40:\n",
        "    return \"30대\"\n",
        "  elif ages >= 40:\n",
        "    return \"40대 이상\"  \n",
        "  else: \n",
        "    return \"정보없음\"\n",
        "\n",
        "\n",
        "bucket_udf = udf(categorizer, StringType() )\n",
        "bucketed = df.withColumn(\"bucket\", bucket_udf(\"ages\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqIO2_3qM6FT",
        "outputId": "660c15d3-7e86-40b9-89f9-843387c0f18b"
      },
      "source": [
        "bucketed.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+----+------+---------+\n",
            "|      date|name|ages|gender|   bucket|\n",
            "+----------+----+----+------+---------+\n",
            "|2021-08-03|   a|  23|    20|     20대|\n",
            "|2021-09-03|   b|  45|    10|40대 이상|\n",
            "|2021-10-03|   c|  10|    20|     10대|\n",
            "|2021-11-03|   d|  60|    20|40대 이상|\n",
            "|2021-08-23|   e| -99|   -99| 정보없음|\n",
            "|2021-09-13|   f|   2|    10| 정보없음|\n",
            "|2021-11-23|   g|  25|    20|     20대|\n",
            "|2021-11-23|   h|  40|    10|40대 이상|\n",
            "|2021-09-05|   j|  33|   -99|     30대|\n",
            "+----------+----+----+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnxIVU6dN287"
      },
      "source": [
        "import pyspark.sql.functions as f\n",
        "\n",
        "bucketed2 = bucketed.withColumn(\"new_gender\", f.when(bucketed.gender == 20,\"여\")\n",
        "    .when(df.gender == 10,\"남\")\n",
        "     #.when(df.gender.isNull() ,\"\")\n",
        "    .otherwise('정보없음'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOfYA5XJQD2Y",
        "outputId": "bf090ca2-13c5-47b5-d963-c3e7ef45e62e"
      },
      "source": [
        "bucketed2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+----+------+---------+----------+\n",
            "|      date|name|ages|gender|   bucket|new_gender|\n",
            "+----------+----+----+------+---------+----------+\n",
            "|2021-08-03|   a|  23|    20|     20대|        여|\n",
            "|2021-09-03|   b|  45|    10|40대 이상|        남|\n",
            "|2021-10-03|   c|  10|    20|     10대|        여|\n",
            "|2021-11-03|   d|  60|    20|40대 이상|        여|\n",
            "|2021-08-23|   e| -99|   -99| 정보없음|  정보없음|\n",
            "|2021-09-13|   f|   2|    10| 정보없음|        남|\n",
            "|2021-11-23|   g|  25|    20|     20대|        여|\n",
            "|2021-11-23|   h|  40|    10|40대 이상|        남|\n",
            "|2021-09-05|   j|  33|   -99|     30대|  정보없음|\n",
            "+----------+----+----+------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSexSfWKpaey",
        "outputId": "dd3d1c37-4fc6-47ef-a128-b3a1d2f5c064"
      },
      "source": [
        "bucketed2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[name: string, ages: bigint, gender: bigint, bucket: string, new_gender: string]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ox8tiZpe6N"
      },
      "source": [
        "#bucketed3=bucketed2.groupBy('bucket','new_gender').agg(f.countDistinct('name').alias('회원 수')).orderBy('bucket','new_gender')\n",
        "bucketed3=bucketed2.groupBy('new_gender','bucket').agg(f.countDistinct('name').alias('회원 수')).orderBy('new_gender','bucket')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48e3_VWvqZSg",
        "outputId": "a9ecc005-2454-49f6-deba-2b2d9ce2d3f0"
      },
      "source": [
        "bucketed3.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------+\n",
            "|new_gender|   bucket|회원 수|\n",
            "+----------+---------+-------+\n",
            "|        남|40대 이상|      2|\n",
            "|        남| 정보없음|      1|\n",
            "|        여|     10대|      1|\n",
            "|        여|     20대|      2|\n",
            "|        여|40대 이상|      1|\n",
            "|  정보없음|     30대|      1|\n",
            "|  정보없음| 정보없음|      1|\n",
            "+----------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jLuLcYYxBbc",
        "outputId": "99df6dbc-f98a-42d9-9b40-5a9450c57afd"
      },
      "source": [
        "val = [(\"2021-08-03\",\"MEM100000000185801\"), (\"2021-09-03\",\"MEM100000000330231\"), (\"2021-10-03\",\"MEM100000000099236\")]\n",
        "data = spark.createDataFrame(val, [\"최근2개월 로그인 날짜\",\"회원ID\"])\n",
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+------------------+\n",
            "|최근2개월 로그인 날짜|            회원ID|\n",
            "+---------------------+------------------+\n",
            "|           2021-08-03|MEM100000000185801|\n",
            "|           2021-09-03|MEM100000000330231|\n",
            "|           2021-10-03|MEM100000000099236|\n",
            "+---------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQbrq5TfwRje",
        "outputId": "17e23035-6f59-440a-d344-4a894720e852"
      },
      "source": [
        "val = [(\"MEM100000000185801\", 23, 20), (\"MEM100000000330231\", 45,10), (\"MEM100000000099236\", 10,20)]\n",
        "data = spark.createDataFrame(val, [\"회원ID\", \"나이\",'성별'])\n",
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+----+\n",
            "|            회원ID|나이|성별|\n",
            "+------------------+----+----+\n",
            "|MEM100000000185801|  23|  20|\n",
            "|MEM100000000330231|  45|  10|\n",
            "|MEM100000000099236|  10|  20|\n",
            "+------------------+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNUO6xZf434H"
      },
      "source": [
        "# PySpark DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsBUOii25OG5"
      },
      "source": [
        "## Create DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYhHCUGr5g3Y"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.window import Window\n",
        "import pyspark.sql.functions as f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gMQ68Gqw1Ii"
      },
      "source": [
        "columns = [\"language\",\"users_count\"]\n",
        "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "rdd = spark.sparkContext.parallelize(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhV_iTrB49ku",
        "outputId": "4fbe0091-1e08-4998-980a-9551820a765c"
      },
      "source": [
        "dfFromRDD1 = rdd.toDF()\n",
        "dfFromRDD1.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r2y89eR4_R0",
        "outputId": "4299c509-a36f-4d3f-a63d-03df643b7dbc"
      },
      "source": [
        "dfFromRDD1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|    _1|    _2|\n",
            "+------+------+\n",
            "|  Java| 20000|\n",
            "|Python|100000|\n",
            "| Scala|  3000|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHd8-Ps85Bkp",
        "outputId": "50863c0e-41e2-4833-f5dc-cad4c2b0546d"
      },
      "source": [
        "columns = [\"language\",\"users_count\"]\n",
        "dfFromRDD1 = rdd.toDF(columns)\n",
        "dfFromRDD1.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- language: string (nullable = true)\n",
            " |-- users_count: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9KPFDa65DTQ"
      },
      "source": [
        "dfFromRDD2 = spark.createDataFrame(rdd).toDF(*columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2L1iGcO5HS5",
        "outputId": "c93453c3-4c88-43e9-fb80-d859fddd5224"
      },
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
        "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
        "  ]\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField(\"firstname\",StringType(),True), \\\n",
        "    StructField(\"middlename\",StringType(),True), \\\n",
        "    StructField(\"lastname\",StringType(),True), \\\n",
        "    StructField(\"id\", StringType(), True), \\\n",
        "    StructField(\"gender\", StringType(), True), \\\n",
        "    StructField(\"salary\", IntegerType(), True) \\\n",
        "  ])\n",
        " \n",
        "df = spark.createDataFrame(data=data2,schema=schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False) # 전체 칼럼 보여줄지 말지 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|id   |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6gMkcie6X43"
      },
      "source": [
        "## Create an Empty DataFrame & RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRSb56Cm5XbM",
        "outputId": "e26bab82-33ff-4bb5-ab58-f65f21993e4d"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "#Creates Empty RDD\n",
        "emptyRDD = spark.sparkContext.emptyRDD()\n",
        "print(emptyRDD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmptyRDD[147] at emptyRDD at NativeMethodAccessorImpl.java:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0acq6QTQ6ajn",
        "outputId": "5b0e7bf7-35e0-4c2f-953e-0b2334f77b57"
      },
      "source": [
        "rdd2= spark.sparkContext.parallelize([])\n",
        "print(rdd2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParallelCollectionRDD[148] at readRDDFromFile at PythonRDD.scala:274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxeYKMAv6eQE"
      },
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType\n",
        "schema = StructType([\n",
        "  StructField('firstname', StringType(), True),\n",
        "  StructField('middlename', StringType(), True),\n",
        "  StructField('lastname', StringType(), True)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1PgnPuR6iBT",
        "outputId": "d6d1021e-d8e4-46d8-8be6-cd1fe611b316"
      },
      "source": [
        "df = spark.createDataFrame(emptyRDD,schema)\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPh878eq6kFx",
        "outputId": "c416accb-a228-4a46-9502-e981ae51bd14"
      },
      "source": [
        "df1 = emptyRDD.toDF(schema)\n",
        "df1.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gmU5X896mjl",
        "outputId": "d16096fd-07e6-4b2e-bab8-5163d30264ce"
      },
      "source": [
        "df1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHk6S7RS6tON",
        "outputId": "72972ce6-ec39-4284-b04c-05de37fab1a9"
      },
      "source": [
        "df2 = spark.createDataFrame([], schema)\n",
        "df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_spjojx6t_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c656764a-1cdd-4ef3-9db6-866619a2faac"
      },
      "source": [
        "df3 = spark.createDataFrame([], StructType([]))\n",
        "df3.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            "\n"
          ]
        }
      ]
    }
  ]
}